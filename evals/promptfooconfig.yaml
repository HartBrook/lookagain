description: "Behavioral evals for lookagain argument handling"

prompts:
  - file://prompt-loader.js

providers:
  - id: anthropic:messages:claude-sonnet-4-20250514
    config:
      max_tokens: 2048

tests:
  # ==================================================================
  # again.md — no arguments (defaults)
  # ==================================================================
  - description: "no arguments → model uses all defaults (auto-fix=true, passes=3, thorough)"
    vars:
      prompt_file: src/commands/again.md
    assert:
      - type: llm-rubric
        value: >
          The response must use default values for all settings since the
          argument string is empty: 3 passes, staged target, auto-fix true,
          thorough model, and max-passes 7. It must describe applying fixes
          for must_fix issues (since auto-fix defaults to true). It should
          NOT say arguments are missing or unavailable — an empty string
          simply means the user wants all defaults.

  # ==================================================================
  # again.md — auto-fix interpretation
  # ==================================================================
  - description: "auto-fix=true → model plans to apply fixes"
    vars:
      prompt_file: src/commands/again.md
      arg_passes: "3"
      arg_target: staged
      arg_auto-fix: "true"
      arg_model: thorough
      arg_max-passes: "7"
    assert:
      - type: llm-rubric
        value: >
          The response must clearly state that it will automatically fix
          or apply fixes for must_fix issues between review passes.
          It should NOT say it will skip fixing or leave fixes to the user.

  - description: "auto-fix=false → model skips fixes"
    vars:
      prompt_file: src/commands/again.md
      arg_passes: "3"
      arg_target: staged
      arg_auto-fix: "false"
      arg_model: thorough
      arg_max-passes: "7"
    assert:
      - type: llm-rubric
        value: >
          The response must clearly state that auto-fix is disabled or false,
          and that it will NOT automatically apply fixes between passes.
          It should not describe applying any code fixes.

  # ==================================================================
  # again.md — passes count
  # ==================================================================
  - description: "passes=5 → model plans exactly 5 initial passes"
    vars:
      prompt_file: src/commands/again.md
      arg_passes: "5"
      arg_target: staged
      arg_auto-fix: "true"
      arg_model: thorough
      arg_max-passes: "7"
    assert:
      - type: icontains
        value: "5"
      - type: llm-rubric
        value: >
          The response must indicate it will run 5 review passes
          (not 3, which is the default). It should plan for exactly
          5 sequential passes before considering additional passes.

  # ==================================================================
  # again.md — model resolution
  # ==================================================================
  - description: "model=fast → reviewer uses haiku"
    vars:
      prompt_file: src/commands/again.md
      arg_passes: "3"
      arg_target: staged
      arg_auto-fix: "true"
      arg_model: fast
      arg_max-passes: "7"
    assert:
      - type: icontains
        value: haiku
      - type: llm-rubric
        value: >
          The response must indicate that the reviewer subagent model
          will be set to haiku, since the model argument is "fast".

  - description: "model=thorough → no explicit model override"
    vars:
      prompt_file: src/commands/again.md
      arg_passes: "3"
      arg_target: staged
      arg_auto-fix: "true"
      arg_model: thorough
      arg_max-passes: "7"
    assert:
      - type: llm-rubric
        value: >
          The response must indicate that for model=thorough, the model
          parameter is omitted from the Task tool call (it inherits the
          current model). It should NOT set the model to haiku or sonnet.

  # ==================================================================
  # again.md — scope resolution
  # ==================================================================
  - description: "target=branch → branch-based diff scope"
    vars:
      prompt_file: src/commands/again.md
      arg_passes: "3"
      arg_target: branch
      arg_auto-fix: "true"
      arg_model: thorough
      arg_max-passes: "7"
    assert:
      - type: llm-rubric
        value: >
          The response must indicate that the scope is branch-based,
          reviewing all changes on the current branch versus the base
          branch. It should reference branch comparison or merge-base.

  # ==================================================================
  # again.md — partial arguments (only auto-fix specified)
  # ==================================================================
  - description: "only auto-fix=false → defaults for everything else, no fixing"
    vars:
      prompt_file: src/commands/again.md
      arg_auto-fix: "false"
    assert:
      - type: llm-rubric
        value: >
          The response must parse auto-fix=false from the argument string
          and use defaults for all other settings (3 passes, staged target,
          thorough model, max-passes 7). It must NOT apply any fixes since
          auto-fix is explicitly false.

  # ==================================================================
  # tidy.md — all flag
  # ==================================================================
  - description: "all=true → removes all runs"
    vars:
      prompt_file: src/commands/tidy.md
      arg_keep: "1"
      arg_all: "true"
    assert:
      - type: llm-rubric
        value: >
          The response must state that ALL run directories will be removed,
          regardless of date. It should not apply any date-based filtering.

  - description: "all=false, keep=3 → date-based retention"
    vars:
      prompt_file: src/commands/tidy.md
      arg_keep: "3"
      arg_all: "false"
    assert:
      - type: llm-rubric
        value: >
          The response must describe calculating a cutoff date by subtracting
          3 days from today, and only removing runs older than that cutoff.
          It should keep runs from the last 3 days.

  # ==================================================================
  # tidy.md — no arguments (defaults)
  # ==================================================================
  - description: "tidy with no arguments → keep=1, all=false"
    vars:
      prompt_file: src/commands/tidy.md
    assert:
      - type: llm-rubric
        value: >
          The response must use default values since the argument string is
          empty: keep=1 (keep runs from the last 1 day) and all=false (do
          NOT remove all runs). It should describe date-based filtering
          with a 1-day retention window. An empty argument string means
          the user wants all defaults — it should NOT say arguments are
          missing or unavailable.
